{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.571491\n",
      "n_neighbors: 3, average score: 0.744377\n",
      "n_neighbors: 5, average score: 0.743685\n",
      "n_neighbors: 10, average score: 0.758969\n",
      "n_neighbors: 20, average score: 0.616425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.044672\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.135035\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.099986\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.004413\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.008329\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.154889\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.050565\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.032678\n",
      "C: 0.100000, gamma: 0.001000, average score: 0.009193\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.180455\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.510518\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.486574\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.127163\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.585159\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.598611\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.612283\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.519028\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.619429\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.655002\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.710181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.\n",
    "\n",
    "To inspect training score on the different folds, the parameter ``return_train_score`` is set to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.005769068600015137, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.026994163494863388, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.05343077528710327, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=-0.003806716708780522, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=-0.023783263158578368, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.05119104194003521, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=0.0047229528262509035, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=-0.010506784418316206, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=-0.041621877193496415, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=0.003123235504414734, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] .... C=0.001, gamma=1, score=-0.014000594686575107, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.04319898992199622, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=-0.0036139668682513277, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.023436593566757535, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=-0.05095443273012812, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=0.015493207276943031, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=0.00655795350875854, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .. C=0.01, gamma=0.01, score=-0.029561493845853045, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.09684593721725188, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.11377637923742569, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.04906119246445373, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.08213318937682956, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.09088421990687567, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.03953706000111323, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.017498976773906993, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.009435582334875292, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=-0.02734408667452759, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.17715765557626928, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.22192100774958345, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.14046962015007414, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5232816739994346, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5497350161891649, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.48339350270951553, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ........ C=0.1, gamma=1, score=0.48480264816473073, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5055382791008973, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ........ C=0.1, gamma=1, score=0.45292951158671874, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.1837192113883085, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.2398722838951345, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.15468191039244072, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6047273372590332, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6082898327108499, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5653238915666097, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .......... C=1, gamma=0.1, score=0.710678236209948, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.5347796790813564, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.7016435368021032, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7650600655582879, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.5884425851849503, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7206203258715845, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6067574418474897, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6070763963568658, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5630492121361308, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6705130639338801, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ...... C=10, gamma=0.01, score=0.49387921504312937, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6260696688705448, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.714533970941589, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ....... C=10, gamma=0.1, score=0.47759491783574454, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.7161192337992834, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8189880963686303, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.5601785332254465, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7748120741706687, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7190028532060524\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>-0.005769</td>\n",
       "      <td>-0.026994</td>\n",
       "      <td>-0.053431</td>\n",
       "      <td>-0.028502</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>-0.006810</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>0.003072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>-0.003807</td>\n",
       "      <td>-0.023783</td>\n",
       "      <td>-0.051191</td>\n",
       "      <td>-0.026036</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>19</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>-0.004654</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>0.002995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>-0.010507</td>\n",
       "      <td>-0.041622</td>\n",
       "      <td>-0.015597</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010395</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.002745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>-0.014001</td>\n",
       "      <td>-0.043199</td>\n",
       "      <td>-0.017814</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>17</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.002876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>-0.003614</td>\n",
       "      <td>-0.023437</td>\n",
       "      <td>-0.050954</td>\n",
       "      <td>-0.025778</td>\n",
       "      <td>0.019442</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.004433</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.002986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.002076      0.000696         0.001391        0.000836   0.001   \n",
       "1       0.001198      0.000211         0.000493        0.000047   0.001   \n",
       "2       0.000973      0.000228         0.000590        0.000080   0.001   \n",
       "3       0.001083      0.000394         0.000515        0.000127   0.001   \n",
       "4       0.000645      0.000151         0.000352        0.000045    0.01   \n",
       "\n",
       "  param_gamma                        params  split0_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}          -0.005769   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}          -0.003807   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}           0.004723   \n",
       "3           1      {'C': 0.001, 'gamma': 1}           0.003123   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}          -0.003614   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0          -0.026994          -0.053431        -0.028502        0.019533   \n",
       "1          -0.023783          -0.051191        -0.026036        0.019455   \n",
       "2          -0.010507          -0.041622        -0.015597        0.019299   \n",
       "3          -0.014001          -0.043199        -0.017814        0.019144   \n",
       "4          -0.023437          -0.050954        -0.025778        0.019442   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               20            0.000075           -0.000737   \n",
       "1               19            0.002047            0.001282   \n",
       "2               16            0.010395            0.010591   \n",
       "3               17            0.009130            0.009875   \n",
       "4               18            0.002257            0.001472   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0           -0.006810         -0.002491         0.003072  \n",
       "1           -0.004654         -0.000442         0.002995  \n",
       "2            0.004673          0.008553         0.002745  \n",
       "3            0.003436          0.007480         0.002876  \n",
       "4           -0.004433         -0.000234         0.002986  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.649650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.636867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.597558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.719003\n",
       "15       1           1         0.692111\n",
       "14       1         0.1         0.649650\n",
       "18      10         0.1         0.636867\n",
       "17      10        0.01         0.597558"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/14_grid_search.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
